# Policy Gap Analyzer (Offline, Local LLM)

A fully **offline-capable policy gap analysis tool** that compares organizational policies against reference frameworks (CIS, MS-ISAC, NIST, etc.) using **local embeddings, semantic similarity, and a local LLM via Ollama**.

> âš ï¸ **Note (Update)**  
> The current codebase runs **fully offline after initial setup**, but **FAISS and DOCX support are optional / roadmap features**.  
> Semantic similarity is currently computed directly using `SentenceTransformer + cosine similarity`.  
> FAISS integration can be added without changing the offline guarantees.

This project is designed for **security audits, compliance testing, and LLM evaluation** without relying on cloud APIs.

---

## ðŸš€ Key Features

- âœ… 100% **offline runtime** (after initial setup)
- âœ… Local **LLM inference via Ollama**
- âœ… **SentenceTransformer embeddings (offline cached)**
- âœ… Optional **FAISS-ready architecture**
- âœ… Supports **TXT / PDF / MD**  
- âš ï¸ DOCX listed for compatibility with planned extensions
- âœ… Batch comparison of multiple policies
- âœ… Deterministic, testable gap detection
- âœ… Designed for **Intel CPU (no GPU required)**

---

## ðŸ§  Architecture Overview

```
Reference Policies â”€â”€â”
                     â”œâ”€â–¶ SentenceTransformer
Test Policies â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
                                â–¼
                      Semantic Similarity
                                â”‚
                                â–¼
                       Gap Candidates
                                â”‚
                                â–¼
                     Local LLM (Ollama)
                                â”‚
                                â–¼
                      Gap Report Files
```

> â„¹ï¸ FAISS can be inserted between embeddings and similarity for large-scale corpora.

---

## ðŸ“¦ Requirements

### System
- Ubuntu 20.04+ / WSL2
- Python **3.9 â€“ 3.12**
- 16 GB RAM recommended
- Intel CPU supported (no CUDA needed)

---

## ðŸ”§ One-Time Online Setup (Required)

### 1ï¸âƒ£ System packages
```bash
sudo apt update
sudo apt install -y python3 python3-pip python3-venv build-essential poppler-utils git curl
```

---

### 2ï¸âƒ£ Install Ollama (Local LLM Runtime)
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

Verify:
```bash
ollama --version
```

---

### 3ï¸âƒ£ Download LLM Model (ONE TIME)
```bash
ollama pull llama3.2:3b
```

---

### 4ï¸âƒ£ Start Ollama Server
```bash
ollama serve
```

---

## ðŸ Python Environment Setup

```bash
python3 -m venv venv
source venv/bin/activate
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt
```

---

## ðŸ—‚ Model & Cache Handling (Offline Guarantee)

> âš ï¸ Important: **SentenceTransformer models must exist in local cache**  
> The code runs with:
```python
SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2", local_files_only=True)
```

Run once with internet:
```bash
python3 - <<'EOF'
from sentence_transformers import SentenceTransformer
SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
print("Model cached")
EOF
```

After this â†’ **no internet required**.

---

## â–¶ï¸ Running the Analyzer

```bash
python3 policy_gap_analyzer.py
```

Input folder:
```
tests/
```

Output folder:
```
reports/
```

---

## ðŸ” Offline Guarantee

| Component | Offline |
|---------|---------|
| Python code | âœ… |
| SentenceTransformer | âœ… (cached) |
| Semantic similarity | âœ… |
| Ollama inference | âœ… |
| FAISS (if added) | âœ… |
| Internet APIs | âŒ |

---

## ðŸ“œ License
MIT
